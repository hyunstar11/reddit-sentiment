{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Brand Insights & Report Generation\n",
    "\n",
    "This notebook covers:\n",
    "1. Brand sentiment comparison\n",
    "2. Narrative theme extraction\n",
    "3. Retail channel attribution\n",
    "4. Sentiment trends over time\n",
    "5. Generating the full HTML report\n",
    "6. Shoe model intelligence\n",
    "7. Brand mention distribution by subreddit\n",
    "8. Purchase intent funnel\n",
    "9. Brand sentiment trend over time\n",
    "10. Posts vs comments per brand\n",
    "\n",
    "> **Prerequisites:** `data/processed/annotated.parquet` must exist (run Notebook 2 or `make analyze`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_path = Path('../data/processed/annotated.parquet')\n",
    "if annotated_path.exists():\n",
    "    df = pd.read_parquet(annotated_path)\n",
    "    print(f'Loaded {len(df):,} annotated records')\n",
    "else:\n",
    "    # Generate synthetic demo data\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    brands_pool = [['Nike'], ['Adidas'], ['New Balance'], ['Hoka'], ['Under Armour'],\n",
    "                   ['Nike', 'Adidas'], ['Li-Ning'], ['Puma'], ['Asics'], []]\n",
    "    channels_pool = [['StockX'], ['GOAT'], ['Nike Direct'], ['Foot Locker'],\n",
    "                     ['StockX', 'GOAT'], [], ['Amazon'], ['Grailed']]\n",
    "    intents = ['completed_purchase', 'seeking_purchase', 'price_discussion',\n",
    "               'availability_info', 'purchase_consideration', None, None, None]\n",
    "    \n",
    "    rows = []\n",
    "    for i in range(500):\n",
    "        brands = random.choice(brands_pool)\n",
    "        sentiment = random.gauss(0.15, 0.4)\n",
    "        rows.append({\n",
    "            'id': f'r{i}', 'subreddit': random.choice(['Sneakers','Nike','Adidas','Running']),\n",
    "            'record_type': 'post' if i < 250 else 'comment',\n",
    "            'score': random.randint(1, 500),\n",
    "            'created_utc': pd.Timestamp('2024-01-01', tz='UTC') + pd.Timedelta(hours=i*3),\n",
    "            'full_text': f'Sample text about sneakers and comfort quality hype #{i}',\n",
    "            'vader_score': sentiment, 'hybrid_score': sentiment,\n",
    "            'transformer_score': None,\n",
    "            'brands': brands,\n",
    "            'channels': random.choice(channels_pool),\n",
    "            'primary_intent': random.choice(intents),\n",
    "            'all_intents': [],\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f'Using synthetic demo data: {len(df):,} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Brand Sentiment Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_sentiment.analysis.brand_comparison import BrandComparisonAnalyzer\n",
    "\n",
    "analyzer = BrandComparisonAnalyzer()\n",
    "metrics = analyzer.compute(df)\n",
    "table = analyzer.comparison_table(df)\n",
    "\n",
    "print(f'Brands detected: {list(metrics.keys())}')\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand sentiment bar chart\n",
    "brands_sorted = table.sort_values('avg_sentiment', ascending=True)\n",
    "colours = ['#22c55e' if s > 0.05 else '#ef4444' if s < -0.05 else '#94a3b8'\n",
    "           for s in brands_sorted['avg_sentiment']]\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=brands_sorted['avg_sentiment'],\n",
    "    y=brands_sorted['brand'],\n",
    "    orientation='h',\n",
    "    marker_color=colours,\n",
    "    text=[f\"{s:+.3f}\" for s in brands_sorted['avg_sentiment']],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title='Brand Sentiment Comparison',\n",
    "    xaxis_title='Avg. Hybrid Sentiment Score',\n",
    "    xaxis=dict(range=[-1, 1]),\n",
    "    height=450, plot_bgcolor='white'\n",
    ")\n",
    "fig.add_vline(x=0, line_dash='dash', line_color='gray')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Narrative Theme Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_sentiment.analysis.narrative import NarrativeThemeExtractor\n",
    "\n",
    "extractor = NarrativeThemeExtractor()\n",
    "narrative = extractor.extract(df)\n",
    "\n",
    "theme_df = pd.DataFrame([\n",
    "    {'theme': k, 'count': v, 'pct': narrative.theme_percentages.get(k, 0)}\n",
    "    for k, v in sorted(narrative.theme_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "])\n",
    "display(theme_df)\n",
    "\n",
    "fig = px.bar(\n",
    "    theme_df, x='pct', y='theme', orientation='h',\n",
    "    title='Narrative Theme Frequency (% of corpus)',\n",
    "    labels={'pct': '% of Posts', 'theme': 'Theme'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top TF-IDF terms\n",
    "if narrative.top_tfidf_terms:\n",
    "    print('Top TF-IDF terms:')\n",
    "    print(', '.join(narrative.top_tfidf_terms[:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retail Channel Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_sentiment.analysis.channel_attribution import ChannelAttributionAnalyzer\n",
    "\n",
    "ch_analyzer = ChannelAttributionAnalyzer()\n",
    "attribution = ch_analyzer.analyze(df)\n",
    "\n",
    "print('Channel Share:')\n",
    "for ch, share in sorted(attribution.channel_share.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'  {ch}: {share:.1f}% ({attribution.channel_counts[ch]} mentions)')\n",
    "\n",
    "# Pie chart\n",
    "if attribution.channel_counts:\n",
    "    ch_df = pd.DataFrame(list(attribution.channel_counts.items()), columns=['channel', 'count'])\n",
    "    fig = px.pie(ch_df.head(8), values='count', names='channel',\n",
    "                 title='Retail Channel Share', hole=0.3)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_sentiment.analysis.trends import SentimentTrendAnalyzer\n",
    "\n",
    "trend_analyzer = SentimentTrendAnalyzer()\n",
    "trends = trend_analyzer.analyze(df)\n",
    "\n",
    "if not trends.monthly.empty:\n",
    "    fig = px.line(\n",
    "        trends.monthly, x='period', y='avg_sentiment',\n",
    "        title='Monthly Average Sentiment',\n",
    "        markers=True\n",
    "    )\n",
    "    fig.add_hline(y=0, line_dash='dash', line_color='gray')\n",
    "    fig.update_layout(yaxis=dict(range=[-1, 1]))\n",
    "    fig.show()\n",
    "    display(trends.monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Full HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_sentiment.reporting.generator import ReportGenerator\n",
    "\n",
    "reports_dir = Path('../data/reports')\n",
    "generator = ReportGenerator(reports_dir=reports_dir)\n",
    "html_path, md_path = generator.generate(df)\n",
    "\n",
    "print(f'HTML Report: {html_path}')\n",
    "print(f'Markdown:    {md_path}')\n",
    "print('\\nOpen the HTML report in your browser to see the full interactive dashboard!')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Shoe Model Intelligence",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from reddit_sentiment.analysis.price_correlation import PriceCorrelationAnalyzer\nimport pandas as pd\n\ncorr = PriceCorrelationAnalyzer()\nresult = corr.analyze(df, pd.DataFrame())  # no eBay data yet\n\n# Show models with enough mentions\ntop_models = result.summary_df[result.summary_df['mentions'] >= 5]\nprint(f'Shoe models with 5+ mentions: {len(top_models)}')\ndisplay(top_models)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from reddit_sentiment.reporting.charts import model_mentions_bar\nimport plotly.io as pio\n\nif result.signals:\n    fig = pio.from_json(model_mentions_bar(result.signals))\n    fig.show()\nelse:\n    print('No shoe model signals detected \u2014 run reddit-sentiment analyze first.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### eBay Price Integration (Premium Column)\n\nThe `price_premium_%` column above is currently empty because no eBay data has been collected yet.\n\nTo populate it:\n1. Set `EBAY_APP_ID` in `.env` (register free at [developer.ebay.com](https://developer.ebay.com))\n2. Run `reddit-sentiment collect --ebay` to fetch sold listings for detected models\n3. Re-run this cell \u2014 `avg_sold_price` and `price_premium_%` will be populated\n\nOnce collected, `PriceCorrelationAnalyzer` computes the Pearson correlation between Reddit sentiment scores and eBay resale premiums, revealing which hype signals actually predict resale value.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "ebeda04c",
   "metadata": {},
   "source": [
    "## 7. Brand Mention Distribution by Subreddit\n",
    "\n",
    "Which brands dominate which communities?"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4dcff7b",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Explode brands so each (post, brand) pair is one row\n",
    "brand_sub = df[df['brands'].map(lambda x: len(x) > 0)].copy()\n",
    "brand_sub = brand_sub.explode('brands')\n",
    "brand_sub = brand_sub[brand_sub['brands'].isin(metrics.keys())]\n",
    "\n",
    "pivot = (\n",
    "    brand_sub.groupby(['brands', 'subreddit'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "fig = px.imshow(\n",
    "    pivot,\n",
    "    title='Brand Mention Heatmap by Subreddit',\n",
    "    color_continuous_scale='Blues',\n",
    "    labels={'color': 'Mentions'},\n",
    "    aspect='auto',\n",
    "    text_auto=True,\n",
    ")\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9becfe9d",
   "metadata": {},
   "source": [
    "## 8. Purchase Intent Funnel\n",
    "\n",
    "How far along the purchase journey are Reddit users?"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5c18dfc",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "intent_df = pd.DataFrame([\n",
    "    {'intent': k.replace('_', ' ').title(), 'count': v}\n",
    "    for k, v in sorted(attribution.intent_funnel.items(), key=lambda x: x[1], reverse=True)\n",
    "    if v > 0\n",
    "])\n",
    "\n",
    "colours = ['#6366f1', '#8b5cf6', '#a855f7', '#c084fc', '#e879f9', '#f0abfc', '#f5d0fe']\n",
    "\n",
    "fig = go.Figure(go.Funnel(\n",
    "    y=intent_df['intent'],\n",
    "    x=intent_df['count'],\n",
    "    textinfo='value+percent initial',\n",
    "    marker=dict(color=colours[:len(intent_df)])\n",
    "))\n",
    "fig.update_layout(title='Purchase Intent Funnel', height=420)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d2e28",
   "metadata": {},
   "source": [
    "## 9. Brand Sentiment Trend Over Time\n",
    "\n",
    "Weekly sentiment trajectory for the top brands \u2014 which brands are gaining or losing momentum?"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6cce338",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "brand_time = df[df['brands'].map(lambda x: len(x) > 0)].copy()\n",
    "brand_time = brand_time.explode('brands')\n",
    "\n",
    "# Keep top 5 brands by mention count\n",
    "top5 = table.head(5)['brand'].tolist()\n",
    "brand_time = brand_time[brand_time['brands'].isin(top5)]\n",
    "\n",
    "if 'created_utc' in brand_time.columns and not brand_time.empty:\n",
    "    brand_time['week'] = (\n",
    "        pd.to_datetime(brand_time['created_utc'])\n",
    "        .dt.to_period('W')\n",
    "        .dt.start_time\n",
    "    )\n",
    "    weekly_brand = (\n",
    "        brand_time.groupby(['week', 'brands'])['hybrid_score']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    fig = px.line(\n",
    "        weekly_brand, x='week', y='hybrid_score', color='brands',\n",
    "        title='Weekly Sentiment Trend by Brand (Top 5)',\n",
    "        markers=True,\n",
    "        labels={'hybrid_score': 'Avg. Sentiment', 'week': 'Week', 'brands': 'Brand'}\n",
    "    )\n",
    "    fig.add_hline(y=0, line_dash='dash', line_color='gray')\n",
    "    fig.update_layout(yaxis=dict(range=[-1, 1]), height=450)\n",
    "    fig.show()\n",
    "else:\n",
    "    print('No timestamp data available for trend analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07cadc3",
   "metadata": {},
   "source": [
    "## 10. Posts vs Comments per Brand\n",
    "\n",
    "Are brands discussed more in post titles or in comment threads?"
   ]
  },
  {
   "cell_type": "code",
   "id": "da11afa8",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'record_type' in df.columns:\n",
    "    brand_type = df[df['brands'].map(lambda x: len(x) > 0)].copy()\n",
    "    brand_type = brand_type.explode('brands')\n",
    "    brand_type = brand_type[brand_type['brands'].isin(metrics.keys())]\n",
    "\n",
    "    breakdown = (\n",
    "        brand_type.groupby(['brands', 'record_type'])\n",
    "        .size()\n",
    "        .reset_index(name='count')\n",
    "    )\n",
    "    # Sort brands by total mentions\n",
    "    order = (\n",
    "        breakdown.groupby('brands')['count']\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .index.tolist()\n",
    "    )\n",
    "    fig = px.bar(\n",
    "        breakdown, x='brands', y='count', color='record_type',\n",
    "        barmode='stack',\n",
    "        category_orders={'brands': order},\n",
    "        title='Posts vs Comments per Brand',\n",
    "        labels={'count': 'Records', 'brands': 'Brand', 'record_type': 'Type'},\n",
    "        color_discrete_map={'post': '#6366f1', 'comment': '#22c55e'}\n",
    "    )\n",
    "    fig.update_layout(height=420)\n",
    "    fig.show()\n",
    "else:\n",
    "    print('record_type column not found.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}